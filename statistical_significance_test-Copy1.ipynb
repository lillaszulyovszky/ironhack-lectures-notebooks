{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "representative-monster",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_1samp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "becoming-degree",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm #(z distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "accessible-headset",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cognitive-semiconductor",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'pd' from 'pandas' (/Users/lilmac/opt/anaconda3/lib/python3.8/site-packages/pandas/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-68c0322e3fe3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'pd' from 'pandas' (/Users/lilmac/opt/anaconda3/lib/python3.8/site-packages/pandas/__init__.py)"
     ]
    }
   ],
   "source": [
    "from scipy.stats import t\n",
    "from pandas import pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "developing-input",
   "metadata": {},
   "source": [
    "### we will perform a one sided test, using the z distribution, to see if the sample mean is significantly less than the known population mean. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regulation-bargain",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the test statistic for our sample \n",
    "# first define the numbers\n",
    "\n",
    "sample_mean = 80.94\n",
    "pop_mean= 85\n",
    "sampl_std= 11.6 \n",
    "n=25 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "divided-recording",
   "metadata": {},
   "outputs": [],
   "source": [
    "# statistic = (sample_mean -pop_mean)/(sampl_std/sqrt(n-1))\n",
    "\n",
    "statistic= (sample_mean-pop_mean)/(sampl_std/math.sqrt(n-1))\n",
    "statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rapid-compound",
   "metadata": {},
   "outputs": [],
   "source": [
    "# is this statistically significant? - 0.05 is convention \n",
    "\n",
    "critical_value= norm.ppf(0.05)\n",
    "critical_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automatic-constant",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the p value and confirm it is less than 0.05 (hence, this is statistically significant)\n",
    "pvalue = norm.cdf(statistic)\n",
    "pvalue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cosmetic-course",
   "metadata": {},
   "source": [
    "#### finding - we have enough evidence acc to our tests, from our small sample, to reject the null hypothesis \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subtle-demographic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# confidence interval for our sample test - useful if plotting the mean collected\n",
    "absoluteZ = abs(norm.ppf(0.05))\n",
    "upperCI = sample_mean + absoluteZ*sampl_std/math.sqrt(n-1)\n",
    "upperCI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "functioning-practice",
   "metadata": {},
   "outputs": [],
   "source": [
    "lowerCI = sample_mean - absoluteZ*sampl_std/math.sqrt(n-1)\n",
    "lowerCI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "packed-player",
   "metadata": {},
   "source": [
    "### what about if our sample had revealed higher than expected weights?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "capable-field",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for a 1 tailed test on the right only (ie mean > 85) \n",
    "# we would calculate the p value and critical value differently \n",
    "# lets work through this with different sample results (higher weight of the 25 boys)\n",
    "\n",
    "sample_mean = 88.94\n",
    "pop_mean = 85\n",
    "pop_std = 11.6\n",
    "n = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "historic-blank",
   "metadata": {},
   "outputs": [],
   "source": [
    "statistic= (sample_mean-pop_mean)/(sampl_std/math.sqrt(n-1))\n",
    "statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "damaged-ghost",
   "metadata": {},
   "outputs": [],
   "source": [
    "pvalue = 1-norm.cdf(statistic)\n",
    "pvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aerial-simple",
   "metadata": {},
   "outputs": [],
   "source": [
    "critical_value= norm.ppf(1-0.05)\n",
    "critical_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "personalized-necklace",
   "metadata": {},
   "source": [
    "### and if we dont care if its below or above the average, just that its different - a 2 tailed t test using the t distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "identified-payroll",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-b5b94c584113>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# create df from csv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'machine.text'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# create df from csv \n",
    "df=pd.read_csv('machine.text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excited-attachment",
   "metadata": {},
   "outputs": [],
   "source": [
    "# same data as for our case study\n",
    "# we are looking for a result that is significantly less or more than the expected mean : \n",
    "\n",
    "sample_mean = 80.94\n",
    "pop_mean= 85\n",
    "sampl_std= 11.6 \n",
    "n=25 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boxed-tender",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculation for test statistic is the same \n",
    "statistic= (sample_mean-pop_mean)/(sampl_std/math.sqrt(n-1))\n",
    "statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fatty-beauty",
   "metadata": {},
   "outputs": [],
   "source": [
    "# on the left side the critical value would be drawn from the t distribution,\n",
    "# using 0.05 split into 2 pieces \n",
    "critical_value=t.ppf( 0.025, n-1)\n",
    "critical_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "valuable-catholic",
   "metadata": {},
   "source": [
    "### as you can see the critical value is higher and harder to achieve on a 2 tailed test. \n",
    "#### in this case, we havent quite reached the threshold to reject the null hypothesis. Another sample is required "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fancy-integrity",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
